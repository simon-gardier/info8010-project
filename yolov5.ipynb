{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1485588",
   "metadata": {},
   "source": [
    "# **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70cba002",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install matplotlib torch torchviz torchvision torchsummary torchviz roboflow\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torchviz import make_dot\n",
    "from torchsummary import summary\n",
    "import torch.utils.data as data\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision import datasets, transforms, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b7d184",
   "metadata": {},
   "source": [
    "# **Util Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    plt.imshow(transforms.functional.to_pil_image(img))\n",
    "    plt.show()\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    images = torch.stack(images, dim=0)\n",
    "    return images, labels\n",
    "\n",
    "def show_image_with_labels(image, labels, class_names=None):\n",
    "    image_np = image.permute(1, 2, 0).numpy()\n",
    "    h, w, _ = image_np.shape\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "    ax.imshow(image_np)\n",
    "\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, bw, bh = label.tolist()\n",
    "        x = (x_center - bw / 2) * w\n",
    "        y = (y_center - bh / 2) * h\n",
    "        box_w = bw * w\n",
    "        box_h = bh * h\n",
    "        rect = patches.Rectangle((x, y), box_w, box_h, linewidth=2, edgecolor='red', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        if class_names:\n",
    "            class_text = class_names[int(class_id)]\n",
    "        else:\n",
    "            class_text = str(int(class_id))\n",
    "        ax.text(x, y - 5, class_text, color='white', fontsize=12,bbox=dict(facecolor='red', alpha=0.5, pad=2))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "classes_types = {\n",
    "    0: 'cow',\n",
    "    1: 'duck',\n",
    "    2: 'flower',\n",
    "    3: 'people',\n",
    "    4: 'pig',\n",
    "    5: 'rabbit',\n",
    "    6: 'sheep',\n",
    "}\n",
    "classes_number = len(classes_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57471f90",
   "metadata": {},
   "source": [
    "# **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afac7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from os import path\n",
    "\n",
    "class MinecraftV1(Dataset):\n",
    "    def __init__(self, root, train=True, valid=False, transform=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "        self.transform = transform\n",
    "\n",
    "        if train:\n",
    "            self.data_path = path.join(root, 'train')\n",
    "        elif valid:\n",
    "            self.data_path = path.join(root, 'valid')\n",
    "        else:\n",
    "            self.data_path = path.join(root, 'test')\n",
    "        \n",
    "        self.images_path = path.join(self.data_path, 'images')\n",
    "        self.labels_path = path.join(self.data_path, 'labels')\n",
    "        self.data_images = []\n",
    "        self.data_labels = []\n",
    "        image_files = os.listdir(self.images_path)\n",
    "        label_files = os.listdir(self.labels_path)\n",
    "        for image_file in image_files:\n",
    "            image_path = path.join(self.images_path, image_file)\n",
    "            self.data_images.append(image_path)\n",
    "\n",
    "        for label_file in label_files:\n",
    "            label_path = path.join(self.labels_path,label_file)\n",
    "            self.data_labels.append(label_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.data_images[idx]\n",
    "        label_path = self.data_labels[idx]\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        with open(label_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        labels = [list(map(float, line.strip().split())) for line in lines]\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return image, labels\n",
    "    \n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mc_train = MinecraftV1(root=os.getcwd(), transform=basic_transform)\n",
    "mc_test = MinecraftV1(root=os.getcwd(), train=False, transform=basic_transform)\n",
    "mc_valid = MinecraftV1(root=os.getcwd(), train=False,valid=True, transform=basic_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86a5b4",
   "metadata": {},
   "source": [
    "# **DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = data.DataLoader(mc_train, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "images, labels = next(iter(trainloader))\n",
    "for i in range(4):\n",
    "    show_image_with_labels(images[i], labels[i], class_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c37134",
   "metadata": {},
   "source": [
    "# **Device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9594731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4727c7c",
   "metadata": {},
   "source": [
    "# **Yolo V5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride = 1):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class FocusBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size =3, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = ConvBlock(in_channels * 4, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat([x[:, :, ::2, ::2],\n",
    "                       x[:, :, 1::2, ::2],\n",
    "                       x[:, :, ::2, 1::2],\n",
    "                       x[:, :, 1::2, 1::2]], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class CSP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,num_blocks):\n",
    "        super().__init__()\n",
    "        hidden_channels = out_channels // 2\n",
    "        self.conv1 = ConvBlock(in_channels, hidden_channels,1)\n",
    "        self.conv2 = ConvBlock(in_channels, hidden_channels,1 )\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            ConvBlock(hidden_channels, hidden_channels, 3)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.conv3 = ConvBlock(2*hidden_channels, out_channels,1)\n",
    "    def forward(self,x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x1 = self.blocks(x1)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        return self.conv3(x)\n",
    "\n",
    "\n",
    "class SPPF(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k = 5):\n",
    "        super().__init__()\n",
    "        hidden_channels = in_channels // 2\n",
    "        self.conv1 = ConvBlock(in_channels, hidden_channels,1 )\n",
    "        self.conv2 = ConvBlock(hidden_channels * 4, out_channels,1)\n",
    "        self.pools = nn.ModuleList([nn.MaxPool2d(kernel_size=k, stride=1, padding=k//2) for _ in range(3)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return self.conv2(torch.cat([x] + [pool(x) for pool in self.pools], 1))\n",
    "\n",
    "class DarkNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stem = FocusBlock(3, 32, 3, 1)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ConvBlock(32, 64, 3, 2),\n",
    "            CSP(64, 64,1)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ConvBlock(64, 128, 3, 2),\n",
    "            CSP(128, 128,2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            ConvBlock(128, 256, 3, 2),\n",
    "            CSP(256, 256,3)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            ConvBlock(256, 512, 3, 2),\n",
    "            CSP(512, 512,1),\n",
    "            SPPF(512, 1024)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        out = self.layer2(x)\n",
    "        out2 = self.layer3(out)\n",
    "        out3 = self.layer4(out2)\n",
    "        return out, out2, out3\n",
    "\n",
    "class PANet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv5_reduce = ConvBlock(1024, 512, 1)\n",
    "        self.conv4_reduce = ConvBlock(256, 512, 1)\n",
    "        self.csp4_td = CSP(1024, 256, num_blocks=1)\n",
    "\n",
    "        self.conv4_reduce2 = ConvBlock(256, 128, 1)\n",
    "        self.conv3_reduce = ConvBlock(128, 128, 1)\n",
    "        self.csp3_td = CSP(256, 128, num_blocks=1)\n",
    "\n",
    "        self.conv3_down = ConvBlock(128, 128, 3, stride=2)\n",
    "        self.csp4_bu = CSP(384, 256, num_blocks=1)\n",
    "\n",
    "        self.conv4_down = ConvBlock(256, 256, 3, stride=2)\n",
    "        self.csp5_bu = CSP(768, 1024, num_blocks=1)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x3, x4, x5):\n",
    "        p5 = self.conv5_reduce(x5)\n",
    "        p5_up = self.upsample(p5)\n",
    "        p4 = self.conv4_reduce(x4)\n",
    "        p4_td = self.csp4_td(torch.cat([p5_up, p4], dim=1))\n",
    "\n",
    "        p4_red = self.conv4_reduce2(p4_td)\n",
    "        p4_up = self.upsample(p4_red)\n",
    "        p3 = self.conv3_reduce(x3)\n",
    "        p3_td = self.csp3_td(torch.cat([p4_up, p3], dim=1))\n",
    "\n",
    "        p3_down = self.conv3_down(p3_td)\n",
    "        p4_bu = self.csp4_bu(torch.cat([p3_down, p4_td], dim=1))\n",
    "\n",
    "        p4_down = self.conv4_down(p4_bu)\n",
    "        p5_bu = self.csp5_bu(torch.cat([p4_down, p5], dim=1))\n",
    "\n",
    "        return p3_td, p4_bu, p5_bu\n",
    "\n",
    "    \n",
    "class HeadDetection(nn.Module):\n",
    "    def __init__(self, in_channels,num_classes,anchor):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.anchor = anchor\n",
    "        self.conv = ConvBlock(in_channels, in_channels * 2,3)\n",
    "        self.final_conv = nn.Conv2d(in_channels * 2, (num_classes + 5) * anchor, kernel_size=1, stride=1, padding=0)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.final_conv(x)\n",
    "        bs, _, h, w = x.shape\n",
    "        x = x.view(bs, self.anchor, self.num_classes + 5, h, w)\n",
    "        return x.permute(0,1,3,4,2)\n",
    "\n",
    "class YOLOv5(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, anchors = None):\n",
    "        super().__init__()\n",
    "        self.backbone = DarkNet()\n",
    "        self.neck = PANet()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if anchors is None:\n",
    "            self.anchors = torch.tensor([\n",
    "                [[10, 13], [16, 30], [33, 23]],\n",
    "                [[30, 61], [62, 45], [59, 119]],\n",
    "                [[116, 90], [156, 198], [373, 326]]\n",
    "            ], dtype=torch.float32)\n",
    "        else:\n",
    "            self.anchors = anchors\n",
    "\n",
    "        self.head_small = HeadDetection(128, num_classes, 3)\n",
    "        self.head_medium = HeadDetection(256, num_classes, 3)\n",
    "        self.head_large = HeadDetection(512, num_classes, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1, out2, out3 = self.backbone(x)\n",
    "        new_out1, new_out2, new_out3 = self.neck(out1, out2, out3)\n",
    "        y_small = self.head_small(new_out1)\n",
    "        y_medium = self.head_medium(new_out2)\n",
    "        y_large = self.head_large(new_out3)\n",
    "        return [y_small, y_medium, y_large]\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YOLOv5(num_classes=classes_number).to(device)\n",
    "\n",
    "summary(model, (3, 640, 640), device=str(device))\n",
    "\n",
    "\n",
    "from torchviz import make_dot\n",
    "\n",
    "params = {name: param for name, param in model.named_parameters() if isinstance(param, torch.Tensor)}\n",
    "\n",
    "x = torch.randn(1, 3, 640, 640).to(device)\n",
    "y = model(x)\n",
    "\n",
    "make_dot(y[0], params=dict(model.named_parameters())).render(\"yolov5_arch\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLOv5(num_classes=classes_number).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e450c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        print(type(labels), type(images))\n",
    "        images = images.to(device)\n",
    "        labels = [label.to(device) for label in labels]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.view(-1, model.output_size), torch.cat(labels).view(-1, model.output_size))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}\")\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        torch.save(model.state_dict(), f\"yolo_epoch_{epoch + 1}.pth\")\n",
    "        print(f\"Model saved at epoch {epoch + 1}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_images, test_labels = next(iter(trainloader))\n",
    "        test_images = test_images.to(device)\n",
    "        outputs = model(test_images)\n",
    "        loss = criterion(outputs.view(-1, model.output_size), torch.cat(test_labels).view(-1, model.output_size))\n",
    "        print(f\"Validation Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info8010",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
